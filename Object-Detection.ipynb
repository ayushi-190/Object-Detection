{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, Image, clear_output\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Function to display images in JupyterLab\n",
    "def show_image(img):\n",
    "    _, img_encoded = cv2.imencode('.png', img)\n",
    "    display(Image(data=img_encoded.tobytes()))\n",
    "\n",
    "# Euclidean Distance Tracker\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        self.center_points = {}  # id -> (cx, cy, w, h)\n",
    "        self.id_count = 0\n",
    "        self.lost_count = {}\n",
    "        self.timeout = 30\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        objects_bbs_ids = []\n",
    "        current_ids = set()\n",
    "\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "            same_object_detected = False\n",
    "\n",
    "            for id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "                size_diff_w = abs(w - pt[2])\n",
    "                size_diff_h = abs(h - pt[3])\n",
    "\n",
    "                distance_threshold = max(100, 0.7 * max(w, h))\n",
    "                size_threshold = max(50, 0.5 * (pt[2] + pt[3]))\n",
    "\n",
    "                if dist < distance_threshold and size_diff_w < size_threshold and size_diff_h < size_threshold:\n",
    "                    self.center_points[id] = (cx, cy, w, h)\n",
    "                    objects_bbs_ids.append([x, y, w, h, id])\n",
    "                    same_object_detected = True\n",
    "                    current_ids.add(id)\n",
    "                    break\n",
    "\n",
    "            if not same_object_detected:\n",
    "                self.center_points[self.id_count] = (cx, cy, w, h)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Handle lost objects\n",
    "        for id in list(self.center_points.keys()):\n",
    "            if id not in current_ids:\n",
    "                self.lost_count[id] = self.lost_count.get(id, 0) + 1\n",
    "                if self.lost_count[id] > self.timeout:\n",
    "                    del self.center_points[id]\n",
    "                    del self.lost_count[id]\n",
    "\n",
    "        return objects_bbs_ids\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('yolov8l.pt')\n",
    "\n",
    "# Video Capture\n",
    "cap = cv2.VideoCapture(r'video2.mp4')\n",
    "tracker = EuclideanDistTracker()\n",
    "\n",
    "# Video Writer setup\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Codec\n",
    "output_video_path = 'output_video.avi'\n",
    "fps = 30  # Frames per second\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Initialize counters and sets to track unique object IDs\n",
    "car_count = 0\n",
    "bike_count = 0\n",
    "animal_count = 0\n",
    "unique_car_ids = set()\n",
    "unique_bike_ids = set()\n",
    "unique_animal_ids = set()\n",
    "\n",
    "# Define labels to count\n",
    "vehicle_labels = ['car', 'motorcycle', 'bicycle']\n",
    "animal_labels = ['dog', 'cat', 'cow']\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)\n",
    "\n",
    "    detections = []\n",
    "    detected_labels = []\n",
    "\n",
    "    for result in results:\n",
    "        for detection in result.boxes:\n",
    "            x1, y1, x2, y2 = detection.xyxy[0].cpu().numpy().astype(int)\n",
    "            conf = detection.conf[0].item()\n",
    "            cls = detection.cls[0].item()\n",
    "            label = model.names[int(cls)]\n",
    "\n",
    "            if label in vehicle_labels + animal_labels and conf > 0.4:\n",
    "                detections.append([x1, y1, x2 - x1, y2 - y1])\n",
    "                detected_labels.append(label)\n",
    "\n",
    "    # Object tracking\n",
    "    boxes_ids = tracker.update(detections)\n",
    "\n",
    "    # Draw detection and tracking results\n",
    "    for idx, box_id in enumerate(boxes_ids):\n",
    "        x, y, w, h, object_id = box_id\n",
    "        label = detected_labels[idx] if idx < len(detected_labels) else \"Unknown\"\n",
    "        cv2.putText(frame, f'{label} ID: {object_id}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "\n",
    "        # Update counts and track unique IDs\n",
    "        if label == 'car' and object_id not in unique_car_ids:\n",
    "            car_count += 1\n",
    "            unique_car_ids.add(object_id)\n",
    "        elif label in ['motorcycle', 'bicycle'] and object_id not in unique_bike_ids:\n",
    "            bike_count += 1\n",
    "            unique_bike_ids.add(object_id)\n",
    "        elif label in animal_labels and object_id not in unique_animal_ids:\n",
    "            animal_count += 1\n",
    "            unique_animal_ids.add(object_id)\n",
    "\n",
    "    # Display counts on the frame\n",
    "    cv2.putText(frame, f'Cars: {car_count}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, f'Bikes: {bike_count}', (10, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, f'Animals: {animal_count}', (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Write the frame to the output video file\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    clear_output(wait=True)  # Clear previous output\n",
    "    show_image(frame)  # Display the frame with detections and counts\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()  # Release the VideoWriter\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
